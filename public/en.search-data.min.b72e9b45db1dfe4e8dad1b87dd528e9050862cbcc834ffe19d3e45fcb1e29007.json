[{"id":0,"href":"/docs/introduction/","title":"Explainability","section":"Docs","content":" Explainability # Explainability is the degree to which a human can understand the cause of a decision (or prediction) made by a prediction model 1.\nTime series tasks # Time series classification Time series forecasting Anomaly detection References # Interpretable Machine Learning: A Guide for Making Black Box Models Explainable, Christoph Molnar\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":1,"href":"/docs/forecasting/introduction/","title":"Introduction","section":"Forecasting","content":" Explainability for time series forecasting # Explainability is the degree to which a human can understand the cause of a decision (or prediction) made by a prediction model 1.\nTypes of time series # type time series only time series + external regressors univariate 1 ✔ 2 ✔ multiple univariate 3 ✔ 4 ✔ multiple hierarchical univariate 5 (phase 2) 6 (phase 2) multivariate 7 ✘ 8 ✘ Domain of explanations # what explain data Explain the time series based on trend, seasonality and cyclic patterns. forecaster Explains the trained forecaster based on the historical time series. forecast Explains the forecast at a certain point in time or a certain time interval. residual Explains the residual on the historical time series to understand where the forecaster is making errors. Scope of explanations # scope description global explanation Explains the forecaster trained on the historical time series. local explanation Explains the forecast made by a forecaster at a certain point in time. group explanation Explains the overall forecast made by a forecaster at a certain time interval. The individual local explanations can be used on each instance and then listed or aggregated for the entire interval. Type of explanations # type description features based Explanation is in terms of features that encode the time series (lag features, date encodings etc.) and external regressors. instance based Explanation is in terms of the importance or certain time points in the historical time series. Examples from supervised learning # ⚡️ features instance global feature importance plots SHAP values (what-if) Partial dependence plots local LIME prototypes and criticisms SHAP influence functions counterfactual explanation (what-if) counterfactual queries Model-agnostic explaninablity # We have access to only fit and predict methods of a forecaster. We have access to training data ? We have access to features ? Challenges # Non-iid nature of data. Robustness. If the the foreecast does not change drastically for the next time point the explanation should not change. Explain prediction intervals and quantile forecasts. Scalability. Interpretable models # Some time series forecasting models are inherently interprtable and we aim to wrap up the model specific interpretation whereever available.\nStatistical models Exponential Smoothing Holt-Winter S/ARIMA/X Croston\u0026rsquo;s models Theta Prohet machine learning models Tree based algorithms like XGBoost, CatBoost Gradient Boosted Machines like LightGBM Gaussian Process Regression deep learning models Recurrent Neural Networks (RNN) Temporal Convolutional Neural Networks (TCNN) Taxonomy # Inspired from here\nReferences # Interpretable Machine Learning: A Guide for Making Black Box Models Explainable, Christoph Molnar\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":2,"href":"/docs/metrics/","title":"Metrics","section":"Docs","content":" Metrics # Evaluating feature based local explanations # Let \\(f\\) be a black box predictor that maps an input \\(\\mathbf{x} \\in \\mathbb{R}^d\\) to an output \\(f(\\mathbf{x}) \\in \\mathbb{R}\\).\nAn explanation function \\(g\\) takes in a predictor \\(f\\) and an instances \\(\\mathbf{x}\\) and returns the feature importance scores \\(g(f,\\mathbf{x}) \\in \\mathbb{R}^d\\).\nLet \\(\\rho: \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^{+}\\) be a distance metric over input instances.\nLet \\(D: \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^{+}\\) be a distance metric over explanations.\nAn evaluation metric \\(\\mu\\) takes in as input a predictor \\(f\\),an explanation fucntion \\(g\\), and input \\(\\mathbf{x}\\), and outputs a scalar \\(\\mu(f,g;\\mathbf{x})\\).\nWe wil mainly focus on these threes evaluation metrics which can be evaluated without access to ground-truth explanations1.\nFaithfulness # (high) faithfulness,relevance,fidelity. The feature importance scores from \\(g\\) should correspond to the importance features of \\(\\mathbf{x}\\) for \\(f\\), such that, when we set a particular set of features \\(\\mathbf{x}_s\\) to a baseline value \\(\\overline{\\mathbf{x}}_s\\), the change in predictor\u0026rsquo;s output should be proportional (measured via correlation) to the sum of the attribution scores of features in \\(\\mathbf{x}_s\\).\nFor a subset of indices \\(S \\subset {1,2,\u0026hellip;,d}\\), let \\(\\mathbf{x}_s = ( \\mathbf{x}_i,i \\in S )\\) a sub-vector of input features. For a given subset size \\(|S|\\), we define faithfullness as\n\\( \\mu_{F}(f,g,|S|;\\mathbf{x}) = \\text{corr}_{S \\in \\binom {d}{|S|}}\\left( \\sum_{i \\in S}g(f,\\mathbf{x})_{i},f(\\mathbf{x})-f(\\mathbf{x}|\\mathbf{x}_s=\\overline{\\mathbf{x}}_s)\\right) \\) The baseline can be the mean of the training data.\nSensitivity # (low) sensitivity, stability, reliability, explanation continuity. If inputs are near each other and their model outputs are similar, then their explanations should be close to each other.\nLet \\(\\mathcal{N}_r(\\mathbf{x})\\) be a neighborhood of datapoints within a radius \\(r\\) of \\(\\mathbf{x}\\).\n\\( \\mathcal{N}_r(\\mathbf{x}) = \\left\\{ \\mathbf{z} \\in \\mathcal{D}_x | \\rho(\\mathbf{x},\\mathbf{z}) \\leq r, f(\\mathbf{x}) = f(\\mathbf{z}) \\right\\} \\) Max Sensitivity\n\\( \\mu_{M}(f,g,r;\\mathbf{x}) = \\max_{z\\in\\mathcal{N}_r(\\mathbf{x})} D(g(f,\\mathbf{x}),g(f,\\mathbf{z})) \\) Average Sensitivity\n\\( \\mu_{A}(f,g,r;\\mathbf{x}) = \\int_{\\mathcal{N}_r(\\mathbf{x})} D(g(f,\\mathbf{x}),g(f,\\mathbf{z})) \\mathbb{P}_{\\mathbf{x}}(\\mathbf{z}) d\\mathbf{z} \\) Complexity # (low) complexity,information gain,sparsity. A complex explantion is one that uses all the \\(d\\) features in its explanation. The simplest explanation would be concentrated on one feature.\nWe define complexity as the entropy of the fractional contribution distribution.\n\\( \\mu_{C}(f,g;\\mathbf{x}) = \\mathbb{E}_{i}\\left[ -\\ln(\\mathbb{P}_{g})\\right] = - \\sum_{i=1}^{d} \\mathbb{P}_{g}(i) \\ln(\\mathbb{P}_{g}(i)) \\) where \\(\\mathbb{P}_{g}\\) is the fractional contribution distribution\n\\( \\mathbb{P}_{g}(i) = \\frac{|g(f,\\mathbf{x})_i|}{\\sum_{j=1}^{d}|g(f,\\mathbf{x})_j|}. \\) References # Evaluating and Aggregating Feature-based Model Explanations, Bhatt, Umang and Weller, Adrian and Moura, José M. F., Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI-20), 2020.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":3,"href":"/docs/forecasting/timeshap/","title":"TimeSHAP","section":"Forecasting","content":" TimeSHAP # code API docs example notebook TimeSHAP is a feature based post-hoc black box explainer to explain the forecast of any univariate time series forecaster using tree-based regressors to build the surrogate model and SHAP(SHapley Additive exPlanations) values for the explanations. For any given univariate time series we first generate a sequence of backtested historical forecasts using an (expanding window) splitter. Using the splitter we split the time series into a sequence of train an test splits. The expanding window splitter uses more and more training data, while keeping the test window size fixed to the forecast horizon. The method is model agnostic in the sense that it needs access to only the fit and predict methods of the forecaster. The forecaster is trained on the train split and evaluated on the test split and all the test split predictions are concatenated to get the backtested historical forecasts for each step of the forecast horizon. We the construct a surrogate time series forecasting task by reducing it to a standard supervised regression problem. For each time point we generate a set of interpretable features (lag features, seasonal features, date time encodings etc) based on which we need to predict the backtested forecasted time series values. The surrogate model is fitted using tree-based regressors like XGBoost, CatBoost,LightGBM etc. Explanation is in now in terms of features that encode the time series. We mainly rely on the TreeSHAP (SHapley Additive exPlanations) algorithm to explain the output of ensemble tree models. In order to improve the sensitivity we extend the above approach by aggregating multiple explanations from bootstrapped versions of the time series.\nTime series forecasting # A univariate time series is a series with a single time-dependent variable. Let \\(f(t):\\mathbb{Z}\\to\\mathbb{R}^1\\) represent a latent univariate time series for any discrete time index \\(t \\in \\mathbb{Z}\\) . We observe a sequence of historical noisy (and potentially missing) values \\(y(t)\\) for \\(t \\in [1,\\dots,T]\\) such that in expectation \\(\\mathbb{E}[y(t)]=f(t)\\) . For example, in the retail domain \\(y(t)\\) could represent the daily sales of a product and \\(f(t)\\) the true latent demand for the product.\nThe task of time series forecasting is to estimate \\(f(t)\\) for all \\(t \u003eT\\) based on the observed historical time series \\(y(t)\\) for \\(t \\in [1,\\dots,T]\\) . When we talk about the forecast, we usually mean the average value of the forecast distribution also known as the point forecast, \\(f(t)\\) , which is the mean ( \\(\\mathbb{E}[y(t)]\\) ) of the forecast distribution. The time series forecast is typically done for a fixed number or periods in the future, refered to as the forecast horizon, \\(h\\) . Let \\(\\hat{f}(T+h)\\) for \\(h \\in [1,\\dots,H]\\) be the forecasted time series for the forecast horizon \\(h\\) based on the historical observed time series \\(y(1),...,y(T)\\) . \\( \\textbf{forecaster model}\\:\\:\\hat{f}(T+h|y(1),...,y(T))\\:\\text{for}\\:h=1,...,H \\) Using the language of supervised learning, \\(y(1),...,y(T)\\) is the training data of \\(T\\) samples based on which we learn/train a forecaster model \\(\\hat{f}\\) . The trained model \\(\\hat{f}\\) is then used to predict/forecast on the test set of \\(H\\) time points in the future. Unlike supervised learing where the model is usually fit once in time series forecasting for many algorithms we will have to continously fit the model before forecasting as more recent data arrives.\nExplainability for forecasting # Explainability is the degree to which a human can understand the cause of a decision (or prediction) made by a prediction model 123.Various notions of explainability (local and global explanations) and explainer algorithms has been studied in classical supervised learning paradigms like classification and regression.\nScope of explanations # An explanation is the answer to either a why-question or a what if-scenario. We define the following three notions of explanations in the context of time series forecasting.\nA local explantion explains the forecast made by a forecaster at a certain point in time. Why is the forecasted sales on July 22, 2019 much higher than the average sales? Will the forecast increase if I increase the offered discount? A global explanation explains the forecaster trained on the historical time series. What are the most important attributes the forecaster relies on to make the forecast? What is the impact of diccount on the sales forecast? A semi-local explanation explains the overall forecast made by a forecaster in a certain time interval. In general this returns one (semi-local) explanation aggregated over all the multiple time steps in the forecast horizon. Why is the forecasted sales over the next 4 weeks much higher? Type of explanations # In the context of time series the explanations can boradly of the following two types.\nFeatures based Explanation is in terms of features that encode the time series (lag features, date encodings etc.) and external regressors. Instance based Explanation is in terms of the importance or certain time points in the historical time series. Type of explainers # An explainer is an algorithm the generates local, semi-local and global explanations for a forecasting algorithm. We can boradly categorize explainers into the following 3 types.\nDirectly interpretable explainers Some time series forecasting algorithms are inherently interpretable by desgin. For example, for an autoregressive model of order \\(p\\) ( \\(AR(p)\\) ) the coefficients correponds to the importance associated with the past \\(p\\) values of the time series. Another example is, Prophet which uses a decomposable additive time series model with three main model components: trend, seasonality, and holidays. The explanation is directly in terms of these 3 components. White-box explainers Though not directly interpretable, some forecasting algorithms can be explained if we have access to the internals of the corresponding forecasting algorithm. For example, for deep neural forecasting algorithms if we have access to the model we can compute saliency maps and activations to explain the inner working of the model. Tree based regression ensembles like XGBoost, CatBoost and LightGBM gprovide global explanations in terms of the feature importance scores. Black-box explainers Such explainers are model agnostic and generally require access to model\u0026rsquo;s predict (and sometimes fit) functions. Given a source black box model, such explainers generally train a surrogate model that is explainable. TimeSHAP # TimeSHAP is a feature based post-hoc black box explainer to explain the forecast of any univariate time series forecaster using tree-based regressors to build the surrogate model and SHAP(SHapley Additive exPlanations) values for the explanations. Surrogate model # The method is model agnostic in the sense that it needs access to only the fit and predict methods of the forecaster. At any time \\(t\\) using all the historical data available so far (that its, \\(y(1),...,y(t)\\) ) we can train the forecaster model \\(f\\) using the fit method. Once the forecaster is trained we can then generate the corresponding \\(H\\) (forecast horizon) forecasts \\( f(t+h|t)=f(t+h|y(1),...,y(t))\\:\\text{for}\\:h=1,...,H, \\) time steps ahead using the predict method. Our goal now is to learn a surrogate model(s) \\(g\\) to predict the forecasts from the forecaster. \\( g(t+h|t)=g(t+h|y(1),...,y(t))\\:\\text{for}\\:h=1,...,H, \\) While the original forecaster learns to predict \\(y(t+h)\\) based on \\(y(1),...,y(t)\\) the surrogate model is trained to predict the forecasts \\(f(t+h)\\) made by the forecaster. Essentially we want to mimic the forecaster using a surrogate model. We choose the surrogate model that can be easily interpreted.\nBacktested historical forecasts # In order to generate data to train the surrogate model we use backtesting. For any given univariate time series we first generate a sequence of backtested historical forecasts using an expanding window splitter. Using the splitter we split the time series into a sequence of train and test splits. The expanding window splitter uses more and more training data, while keeping the test window size fixed to the forecast horizon. The forecaster is trained on the train split and evaluated on the test split and all the test split predictions are concatenated to get the backtested historical forecasts for each step of the forecast horizon.\nThis is one of the most computationally expensive steps since for a time series of length \\(n\\) we will have to potentially invoke `fit` and `predict` roughly \\(O(n)\\) times to generate the backtested forecasts. - This can be effficiently parallelized since each task can be executed independently. In our implementation we use [ray](https://github.com/ray-project/ray) to parallelize this. - For computationally expensive `fit` models it may be cheaper to forecast without full refitting. However we may need to pass the context/historical time series so far to do the forecast. Some forecasters have a light weight `update` method has the same signature as train but does not do refitting and only does minimal context updates to make the prediction. - Certain forecasting algorithms train one large model based on large number of multiple univariate time series. In such scenarios we completely avoid refitting the model and rely only on the `predict` method to generate the in-sample forecasts and build a surrogate model. While this avoids backtesting and can potentially overfit, since the model is trained or large number of time series this may be fine. Regressor reduction # We now have an original time series and the corresponding backtested forecast time series for each step of the forecast horizon. The goal of the surrogate model is to learn to predict the backtested forecast time series based on on the original time series. We construct a surrogate time series forecasting task by reducing it to a standard supervised regression problem.\nA common machine learning approach to time series forecasting is to reduce it to a standard supervised regression problem. A standard supervised regression task takes as input a \\(d\\) -dimensional feature vector \\(\\mathbf{x}\\in\\mathbb{R}^d\\) and predicts a scalar \\(y \\in \\mathbb{R}\\) . The regressor \\(y = f(\\mathbf{x})\\) is learnt based on a labelled training dataset \\(\\left(\\mathbf{x}_i,y_i\\right)\\) , for \\(i=1,..,n\\) samples. However there is no direct concept of input features ( \\(\\mathbf{x}\\) ) and output target ( \\(y\\) ) for a time series. Instead, we must choose the backtested time series forecast values as the variable to be predicted and use various time series feature engineering techniques (like lag features, date time encodings etc.) to construct the features from the original time series.\nInterpretable features # Essentially, for each time point \\(t\\) we generate a feature vector \\(\\mathbf{x}(t) \\in\\mathbb{R}^d\\) based on the original time series values observed so far based on which we need to predict the backtested forecast time series for each step in the forecast horizon \\(y(t) \\in\\mathbb{R}\\) . The table below is a list of features we use. See here for more details. We generally like the features to be interpretable in the sense that the end user of the explanation should be able to comprehend the meaning of these features.\nThe feature vector \\(\\mathbf{x}(t)\\) needs to be constructed only based on the time step \\(t\\) and the historical values of the time series \\(y(1),...,y(t-1)\\) and should not use the current time series value \\(y(t)\\) . feature name description sales(t-3) The value of the time series (sales) at the (t-3) previous time step. sales(t-2) The value of the time series (sales) at the (t-2) previous time step. sales(t-1) The value of the time series (sales) at the (t-1) previous time step. sales(t-2*365) The value of the time series (sales) at the (t-2*365) previous time step. sales(t-1*365) The value of the time series (sales) at the (t-1*365) previous time step. sales_min(t-1,t-3) The min of the past 3 values in the sales time series. sales_mean(t-1,t-3) The mean of the past 3 values in the sales time series. sales_max(t-1,t-3) The max of the past 3 values in the sales time series. sales_min(0,t-1) The min of all the values so far in the sales time series. sales_mean(0,t-1) The mean of all the values so far in the sales time series. sales_max(0,t-1) The max of all the values so far in the sales time series. year The year. month The month name of the year from January to December. day_of_year The ordinal day of the year from 1 to 365. day_of_month The ordinal day of the month from 1 to 31. week_of_year The ordinal week of the year from 1 to 52. week_of_month The ordinal week of the month from 1 to 4. day_of_week The day of the week from Monday to Sunday. is_weekend Indicates whether the date is a weekend or not. quarter The ordinal quarter of the date from 1 to 4. season The season Spring/Summer/Fall/Winter. fashion_season The fashion season Spring/Summer (January to June) or Fall/Winter (July to December). is_month_start Indicates whether the date is the first day of the month. is_month_end Indicates whether the date is the last day of the month. is_quarter_start Indicates whether the date is the first day of the quarter. is_quarter_end Indicates whether the date is the last day of the quarter. is_year_start Indicates whether the date is the first day of the year. is_year_end Indicates whether the date is the last day of the year. is_leap_year Indicates whether the date belongs to a leap year. hour The hours of the day. minute The minutes of the hour. second The seconds of the minute. holiday-IN Indicates whether the date is a IN holiday or not. t Feature to model simple polynomial (of degree 1) trend in sales. t^2 Feature to model simple polynomial (of degree 2) trend in sales. **External regressors** Classical time series forecasting algorithms esentially learn a model to forecast based on the historical values of the time series. In many domains, the value of the time series depends on several external time series which we refer to as related external regressors. For example in the retail domain, the sales is potentially influence by discount, promotion, events, weather etc. Each external regressor in itself is a time series and some methods allow to explicity include external regressors to improve forecasting. If external regressors are avaiable we can also encode them as interpretable features using similar features as above. Typically some exeternal regressors can be **forwad looking**. For example, the discount that will be used iin the future is typically planned by the retailer in advance. feature name description discount(t-3) The value of the time series (discount) at the (t-3) previous time step. discount(t-2) The value of the time series (discount) at the (t-2) previous time step. discount(t-1) The value of the time series (discount) at the (t-1) previous time step. discount(t) The value of the time series (discount) at the current time step. Multi-step forecasting # In the last section we described some of the commonly used methods to transform the original time series to a set of interpretable features. Recall that we have \\(H\\) backtested time series forecats which are to be used as targets to learn the surrogate regressor model. Here we will desxribe common strategies4 that can be used used for multi-step forecasting to regression reduction.\nRecursive # A single regressor model is fit for one-step-ahead forecast horizon and then called recursively to predict multiple steps ahead. Let \\(\\mathcal{G}(y(1),...,y(t))\\) be the one-step ahead surrogate forecaster that has been learnt based on the training data, where the forecaster predicts the one-step ahead forecast using features based on the time series values till \\(t\\) , that is, \\(y(1),...,y(t)\\) . The forecasts from the surrogate models are made recusively as follows, \\( g(t+1|t) = \\mathcal{G}(y(1),...,y(t)). \\) For \\(h=2,3,...,H\\) \\( g(t+h|t) = \\mathcal{G}(y(1),...,y(t),g(t+1|t),...,g(t+h-1|t)). \\) For example,\nhorizon forecast strategy 1 \\( g(t+1|t) \\) \\( \\mathcal{G}(y(1),...,y(t)) \\) 2 \\( g(t+2|t) \\) \\( \\mathcal{G}(y(1),...,y(t),g(t+1|t)) \\) h \\( g(t+h|t) \\) \\( \\mathcal{G}(y(1),...,y(t),g(t+1|t),...,g(t+h-1|t)) \\) A well-known drawback of the recursive method is its sensitivity to the estimation error, since estimated values, instead of actual ones, are more and more used when we get further in the future forecasts. Direct # A separate regressor model is fit for each step ahead in the forecast horizon and then independently applied to predict multiple steps ahead. Let \\(\\mathcal{G}_h(y(1),...,y(t))\\) be the h-step ahead surrogate forecaster that has been learnt based on the training data, where the forecaster predicts the h-step ahead forecast using features based on the time series values till \\(t\\) , that is, \\(y(1),...,y(t)\\) . The forecasts are made directly as follows, \\( g(t+h|t) = \\mathcal{G}_h(y(1),...,y(t))\\text{ for }h=1,2,...,H \\) For example,\nhorizon forecast strategy 1 \\( g(t+1|t) \\) \\( \\mathcal{G}_1(y(1),...,y(t)) \\) 2 \\( g(t+2|t) \\) \\( \\mathcal{G}_2(y(1),...,y(t)) \\) h \\( g(t+h|t) \\) \\( \\mathcal{G}_h(y(1),...,y(t)) \\) Since the Direct strategy does not use any approximated values to compute the forecasts, it is not prone to any accumulation of errors. However since the models are learned independently no statistical dependencies between the predictions is considered. This strategy also demands a large computational time since the number of models to learn is equal to the size of the forecast horizon. DirRec # The DirRec strategy combines the architectures and the principles underlying the Direct and the Recursive strategies. DirRec computes the forecasts with different models for every horizon (like the Direct strategy) and, at each time step, it enlarges the set of inputs by adding variables corresponding to the forecasts of the previous step (like the Recursive strategy).\n\\( g(t+1|t) = \\mathcal{G}_1(y(1),...,y(t)) \\) For \\(h=2,3,...,H\\) \\( g(t+h|t) = \\mathcal{G}_h(y(1),...,y(t),g(t+1|t),...,g(t+h-1|t)) \\) For example,\nhorizon forecast strategy 1 \\( g(t+1|t) \\) \\( \\mathcal{G}_1(y(1),...,y(t)) \\) 2 \\( g(t+2|t) \\) \\( \\mathcal{G}_2(y(1),...,y(t),g(t+1|t)) \\) h \\( g(t+h|t) \\) \\( \\mathcal{G}_h(y(1),...,y(t),g(t+1|t),...,g(t+h-1|t)) \\) Tree ensemble regressors # So far, for each time point we generate a set of interpretable features (lag features, seasonal features, date time encodings etc) based on which we need to predict the backtested forecasted time series values. The surrogate model is then fitted using tree-based regressors like XGBoost, CatBoost,LightGBM etc.\nSHapley Additive exPlanations # While in general we can use any regressor we prefer tree-based ensembles like XGBoost, CatBoost and LightGBM since they are resonably accurate and more importantly support fast explaninablity algorithms like TreeSHAP which we reply on for the various explanations. Explanation is in now in terms of features that encode the time series. We mainly rely on the TreeSHAP (SHapley Additive exPlanations) algorithm to explain the output of ensemble tree models. SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions. 56\nGlobal explanations # A global explanation explains the forecaster trained on the historical time series. The explanation type can be one of following four types.\nNote that the recurisve strategy has only one model, while the direct and the dirrec strategies have \\(H\\) models corresponding to each step of the forecasting horizon. Hence there will be a possible seprate global explanation for each model based on the forecast horizon. SHAP feature importance # The importance score for each features based on the shap values. Specifically this is the mean absolute value of the shap values for each feature across the entire dataset. To get an overview of which features are most important for a model we can compute the SHAP values of every feature for every sample. We can then take the mean absolute value of the SHAP values for each feature to get a feature importance score for each feature.\nFeature importance # The relative contribution of each feature to the model. A higher value of this score when compared to another feature implies it is more important for generating a forecast. Feature importance provides a score that indicates how useful or valuable each feature was in the construction of the boosted decision trees within the model. The more an attribute is used to make key decisions with decision trees, the higher its relative importance. Feature importance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The feature importances are then averaged across all of the the decision trees within the model. The gain is the most relevant attribute to interpret the relative importance of each feature. The gain implies the relative contribution of the corresponding feature to the model calculated by taking each feature’s contribution for each tree in the model. A higher value of this metric when compared to another feature implies it is more important for generating a prediction.\nPartial dependence plot # The partial dependence plot (PDP) for a feature shows the marginal effect the feature has on the forecast (from the surrogate model). The PDP shows how the average prediction in your dataset changes when a particular feature is changed. The partial dependence function at a particular feature value represents the average prediction if we force all data points to assume that feature value.\nThe calculation for the partial dependence plots has a causal interpretation. One way to think about PDP is that it is an **intervention query**. We intervene on a feature and measure the changes in the predictions. In doing so, we analyze the causal relationship between the feature and the prediction. The assumption of independence is the biggest issue with PDP plots. It is assumed that the feature(s) for which the partial dependence is computed are not correlated with other features. SHAP dependence plot # The shap dependence plot (SDP) for each feature shows the mean shap value for a particular features across the entire dataset. This shows how the model depends on the given feature, and is like a richer extenstion of the classical partial dependence plots.\nLocal explanations # A local explantion explains the forecast made by a forecaster at a certain point in time.\nSHAP explanation # SHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations. While SHAP values can explain the output of any machine learning model, high-speed exact algorithms are available for tree ensemble methods\nThe SHAP explanation shows features contributing to push the forecasted sales from the base value (the average sales) to the forecaster model output. Features pushing the forecast higher are shown in blue and those pushing the forecast lower are in red.\nThis time instance (Mon Jul 1 00:00:00 2019) has a forecasted sales (5028.76), 2579.59 units higher than the average (2449.17) mainly because of the discount(t) (40.50) and sales(t-1) (4242.54) while sales(t-2*52) (4375.00) was trying to push it lower.\nLocal partial dependence plot # The (local) PDP for a given feature shows how the forecast (from the surrogate model) varies as the feature value changes.\nLocal SHAP dependence plot # The (local) SDP for a given feature shows how the shap value varies as the feature value changes.\nSemi-local explanations # A semi-local explanation explains the overall forecast made by a forecaster in a certain time interval. In general this returns one (semi-local) explanation aggregated over all the multiple time steps in the forecast horizon.\nSHAP feature importance # The importance score for each feature which is the corresponding shap value for that feature.\nPartial dependence plot # The PDP for a given feature shows how the forecast (from the surrogate model) varies as the feature value changes.\nSHAP dependence plot # The SDP for a given feature shows how the shap value varies as the feature value changes.\nExplaining prediction intervals # The same setup can also be used to explain the width of the prediction interval. Instead of regressing on the mean forecast from the forecaster we can regress on the width of the prediction interval.\nBootstrapped ensemble # In order to improve the sensitivity we extend the above approach by aggregating multiple explanations from bootstrapped versions of the time series.\nExamples # Naive # The forecast is the value of the last observation. \\( f(t+h|t) = y(t),\\text{ for }h=1,2,... \\) aix360ts from aix360ts.forecasting.forecasters import Naive from aix360ts.forecasting.explainers import TimeSHAP forecaster = Naive() explainer = TimeSHAP(forecaster=forecaster) forecaster global - SHAP global - PDP local - SHAP local - PDP SeasonalNaive # The forecast is the value of the last observation from the same season of the year. For example, with monthly data, the forecast for all future February values is equal to the last observed February value.\naix360ts from aix360ts.forecasting.forecasters import SeasonalNaive from aix360ts.forecasting.explainers import TimeSHAP forecaster = SeasonalNaive(m=52) explainer = TimeSHAP(forecaster=forecaster) forecaster global - SHAP global - PDP local - SHAP local - PDP MovingAverage # A moving average forecast of order \\(k\\) , or, \\(MA(k)\\) , is the mean of the last \\(k\\) observations of the time series.\naix360ts from aix360ts.forecasting.forecasters import MovingAverage from aix360ts.forecasting.explainers import TimeSHAP forecaster = MovingAverage(k=6) explainer = TimeSHAP(forecaster=forecaster) forecaster global - SHAP global - PDP local - SHAP local - PDP Simple Exponential Smoothing # The forecast is the exponentially weighted average of its past values. The forecast can also be interpreted as a weighted average between the most recent observation and the previous forecast.\naix360ts from aix360ts.forecasting.forecasters import SES from aix360ts.forecasting.explainers import TimeSHAP forecaster = SES(alpha=0.5) explainer = TimeSHAP(forecaster=forecaster) forecaster global - SHAP global - PDP local - SHAP local - PDP Prophet # Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects.\naix360ts from aix360ts.forecasting.forecasters import Prophet from aix360ts.forecasting.explainers import TimeSHAP forecaster = Prophet() explainer = TimeSHAP(forecaster=forecaster) forecaster global - SHAP global - PDP local - SHAP local - PDP XGBoost # Forecasting to Regression reduction using XGBoost.\naix360ts from aix360ts.forecasting.forecasters import RegressorReduction from aix360ts.forecasting.explainers import TimeSHAP forecaster = RegressorReduction() explainer = TimeSHAP(forecaster=forecaster) forecaster global - SHAP global - PDP local - SHAP local - PDP References # Interpretable Machine Learning: A Guide for Making Black Box Models Explainable, Christoph Molnar\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nExplanation in Artificial Intelligence: Insights from the Social Sciences, Tim Miller\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTowards A Rigorous Science of Interpretable Machine Learning, Finale Doshi-Velez, Been Kim\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBontempi G., Ben Taieb S., Le Borgne YA. (2013) Machine Learning Strategies for Time Series Forecasting. In: Aufaure MA., Zimányi E. (eds) Business Intelligence. eBISS 2012. Lecture Notes in Business Information Processing, vol 138. Springer, Berlin, Heidelberg.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://github.com/slundberg/shap\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nLundberg, S.M., Erion, G., Chen, H. et al. From local explanations to global understanding with explainable AI for trees. Nat Mach Intell 2, 56–67 (2020).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":4,"href":"/docs/forecasting/features/","title":"Interpretable features","section":"Forecasting","content":" Encoding time series as interpretable features # A common machine learning approach to time series forecasting is to reduce it to a standard supervised regression problem. A regression task takes as input a \\(d\\)-dimensional feature vector \\(\\mathbf{x}\\in\\mathbb{R}^d\\) and predicts a scalar \\(y \\in \\mathbb{R}\\). The regressor \\(y = f(\\mathbf{x})\\) is learnt based on a labelled training dataset \\(\\left(\\mathbf{x}_i,y_i\\right)\\), for \\(i=1,..,n\\) samples. However there is do direct concept of input features (\\(\\mathbf{x}\\)) and output target (\\(y\\)) for a time series. Instead, we must choose the time series values to be forecasted as the variable to be predicted and use various feature engineering to construct the features that will be used to make predictions for future time steps. For each time point \\(t\\) we generate a feature vector \\(\\mathbf{x}(t) \\in\\mathbb{R}^d\\) based on which we need to predict the observed time series value \\(y(t) \\in\\mathbb{R}\\). Here we describe some of the commonly used methods to transform a time series to feature matrix.\nThe feature vector \\\\(\\mathbf{x}(t)\\\\) needs to be constructed only based on the time step \\\\(t\\\\) and the historical values of the time series \\\\(y(1),...,y(t-1)\\\\) and should not use the current time series value \\\\(y(t)\\\\). Lag features # code example The value of the time series at previous time steps. Lag features are the classical way that time series forecasting problems are transformed into supervised learning problems.\naix360ts ```python from aix360ts.transformers import LagFeatures transformer = LagFeatures(lags=3) ``` input ``` sales date 2017-01-01 21.0 2017-01-02 18.0 2017-01-03 9.0 2017-01-04 18.0 2017-01-05 15.0 ... ... 2019-12-27 923.0 2019-12-28 1194.0 2019-12-29 1341.0 2019-12-30 920.0 2019-12-31 748.0 [1095 rows x 1 columns] ``` ouput ``` sales(t-3) sales(t-2) sales(t-1) date 2017-01-01 NaN NaN NaN 2017-01-02 NaN NaN 21.0 2017-01-03 NaN 21.0 18.0 2017-01-04 21.0 18.0 9.0 2017-01-05 18.0 9.0 18.0 ... ... ... ... 2019-12-27 796.0 1178.0 852.0 2019-12-28 1178.0 852.0 923.0 2019-12-29 852.0 923.0 1194.0 2019-12-30 923.0 1194.0 1341.0 2019-12-31 1194.0 1341.0 920.0 [1095 rows x 3 columns] ``` features | | description | type | |:-----------|:----------------------------------------------------------------------|:-----------| | sales(t-3) | The value of the time series (sales) at the (t-3) previous time step. | continuous | | sales(t-2) | The value of the time series (sales) at the (t-2) previous time step. | continuous | | sales(t-1) | The value of the time series (sales) at the (t-1) previous time step. | continuous | Seasonal lag features # code example The value of the time series at time steps for the previous seasons. For example, with monthly data, the feature for February is equal to the last observed February value.\naix360ts ```python from aix360ts.transformers import SeasonalLagFeatures transformer = SeasonalLagFeatures(lags=2, m=365) ``` input ``` sales date 2017-01-01 21.0 2017-01-02 18.0 2017-01-03 9.0 2017-01-04 18.0 2017-01-05 15.0 ... ... 2019-12-27 923.0 2019-12-28 1194.0 2019-12-29 1341.0 2019-12-30 920.0 2019-12-31 748.0 [1095 rows x 1 columns] ``` ouput ``` sales(t-2*365) sales(t-1*365) date 2017-01-01 NaN NaN 2017-01-02 NaN NaN 2017-01-03 NaN NaN 2017-01-04 NaN NaN 2017-01-05 NaN NaN ... ... ... 2019-12-27 428.0 463.0 2019-12-28 440.0 607.0 2019-12-29 700.0 778.0 2019-12-30 894.0 1038.0 2019-12-31 828.0 531.0 [1095 rows x 2 columns] ``` features | | description | type | |:---------------|:--------------------------------------------------------------------------|:-----------| | sales(t-2*365) | The value of the time series (sales) at the (t-2*365) previous time step. | continuous | | sales(t-1*365) | The value of the time series (sales) at the (t-1*365) previous time step. | continuous | Rolling window features # code example Rolling window statistics (mean,max,min).\naix360ts ```python from aix360ts.transformers import RollingWindowFeatures transformer = RollingWindowFeatures(window=3) ``` input ``` sales date 2017-01-01 21.0 2017-01-02 18.0 2017-01-03 9.0 2017-01-04 18.0 2017-01-05 15.0 ... ... 2019-12-27 923.0 2019-12-28 1194.0 2019-12-29 1341.0 2019-12-30 920.0 2019-12-31 748.0 [1095 rows x 1 columns] ``` ouput ``` sales_min(t-1,t-3) sales_mean(t-1,t-3) sales_max(t-1,t-3) date 2017-01-01 NaN NaN NaN 2017-01-02 NaN NaN NaN 2017-01-03 NaN NaN NaN 2017-01-04 9.0 16.000000 21.0 2017-01-05 9.0 15.000000 18.0 ... ... ... ... 2019-12-27 796.0 942.000000 1178.0 2019-12-28 852.0 984.333333 1178.0 2019-12-29 852.0 989.666667 1194.0 2019-12-30 923.0 1152.666667 1341.0 2019-12-31 920.0 1151.666667 1341.0 [1095 rows x 3 columns] ``` features | | description | type | |:--------------------|:--------------------------------------------------------|:-----------| | sales_min(t-1,t-3) | The min of the past 3 values in the sales time series. | continuous | | sales_mean(t-1,t-3) | The mean of the past 3 values in the sales time series. | continuous | | sales_max(t-1,t-3) | The max of the past 3 values in the sales time series. | continuous | Expanding window features # code example Expanding window statistics (mean,max,min).\naix360ts ```python from aix360ts.transformers import ExpandingWindowFeatures transformer = ExpandingWindowFeatures() ``` input ``` sales date 2017-01-01 21.0 2017-01-02 18.0 2017-01-03 9.0 2017-01-04 18.0 2017-01-05 15.0 ... ... 2019-12-27 923.0 2019-12-28 1194.0 2019-12-29 1341.0 2019-12-30 920.0 2019-12-31 748.0 [1095 rows x 1 columns] ``` ouput ``` sales_min(0,t-1) sales_mean(0,t-1) sales_max(0,t-1) date 2017-01-01 21.0 21.000000 21.0 2017-01-02 18.0 19.500000 21.0 2017-01-03 9.0 16.000000 21.0 2017-01-04 9.0 16.500000 21.0 2017-01-05 9.0 16.200000 21.0 ... ... ... ... 2019-12-27 9.0 364.901008 1907.0 2019-12-28 9.0 365.660256 1907.0 2019-12-29 9.0 366.552608 1907.0 2019-12-30 9.0 367.058501 1907.0 2019-12-31 9.0 367.406393 1907.0 [1095 rows x 3 columns] ``` features | | description | type | |:------------------|:------------------------------------------------------------|:-----------| | sales_min(0,t-1) | The min of all the values so far in the sales time series. | continuous | | sales_mean(0,t-1) | The mean of all the values so far in the sales time series. | continuous | | sales_max(0,t-1) | The max of all the values so far in the sales time series. | continuous | Date features # code example Date related features.\naix360ts ```python from aix360ts.transformers import DateFeatures transformer = DateFeatures(encode_cyclical_features=False) ``` input ``` sales date 2017-01-01 21.0 2017-01-02 18.0 2017-01-03 9.0 2017-01-04 18.0 2017-01-05 15.0 ... ... 2019-12-27 923.0 2019-12-28 1194.0 2019-12-29 1341.0 2019-12-30 920.0 2019-12-31 748.0 [1095 rows x 1 columns] ``` ouput ``` year month day_of_year day_of_month week_of_year week_of_month ... is_month_end is_quarter_start is_quarter_end is_year_start is_year_end is_leap_year date ... 2017-01-01 2017 January 1 1 52 1 ... no yes no yes no no 2017-01-02 2017 January 2 2 1 1 ... no no no no no no 2017-01-03 2017 January 3 3 1 1 ... no no no no no no 2017-01-04 2017 January 4 4 1 1 ... no no no no no no 2017-01-05 2017 January 5 5 1 1 ... no no no no no no ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2019-12-27 2019 December 361 27 52 4 ... no no no no no no 2019-12-28 2019 December 362 28 52 4 ... no no no no no no 2019-12-29 2019 December 363 29 52 5 ... no no no no no no 2019-12-30 2019 December 364 30 1 5 ... no no no no no no 2019-12-31 2019 December 365 31 1 5 ... yes no yes no yes no [1095 rows x 18 columns] ``` features | | description | type | |:-----------------|:--------------------------------------------------------------------------------------|:------------| | year | The year. | ordinal | | month | The month name of the year from January to December. | cyclical | | day_of_year | The ordinal day of the year from 1 to 365. | cyclical | | day_of_month | The ordinal day of the month from 1 to 31. | cyclical | | week_of_year | The ordinal week of the year from 1 to 52. | cyclical | | week_of_month | The ordinal week of the month from 1 to 4. | cyclical | | day_of_week | The day of the week from Monday to Sunday. | cyclical | | is_weekend | Indicates whether the date is a weekend or not. | binary | | quarter | The ordinal quarter of the date from 1 to 4. | cyclical | | season | The season Spring/Summer/Fall/Winter. | categorical | | fashion_season | The fashion season Spring/Summer (January to June) or Fall/Winter (July to December). | categorical | | is_month_start | Indicates whether the date is the first day of the month. | binary | | is_month_end | Indicates whether the date is the last day of the month. | binary | | is_quarter_start | Indicates whether the date is the first day of the quarter. | binary | | is_quarter_end | Indicates whether the date is the last day of the quarter. | binary | | is_year_start | Indicates whether the date is the first day of the year. | binary | | is_year_end | Indicates whether the date is the last day of the year. | binary | | is_leap_year | Indicates whether the date belongs to a leap year. | binary | Time features # code example Time related features.\naix360ts ```python from aix360ts.transformers import TimeFeatures transformer = TimeFeatures(encode_cyclical_features=False) ``` input ``` sales date 2017-01-01 21.0 2017-01-02 18.0 2017-01-03 9.0 2017-01-04 18.0 2017-01-05 15.0 ... ... 2019-12-27 923.0 2019-12-28 1194.0 2019-12-29 1341.0 2019-12-30 920.0 2019-12-31 748.0 [1095 rows x 1 columns] ``` ouput ``` hour minute second date 2017-01-01 0 0 0 2017-01-02 0 0 0 2017-01-03 0 0 0 2017-01-04 0 0 0 2017-01-05 0 0 0 ... ... ... ... 2019-12-27 0 0 0 2019-12-28 0 0 0 2019-12-29 0 0 0 2019-12-30 0 0 0 2019-12-31 0 0 0 [1095 rows x 3 columns] ``` features | | description | type | |:-------|:---------------------------|:---------| | hour | The hours of the day. | cyclical | | minute | The minutes of the hour. | cyclical | | second | The seconds of the minute. | cyclical | Encoding Cyclical Features # May time attributes like month, day_of_year, hour etc. all occur in specific cycles and are refered to as cyclical features. One way to encode cyclical features is via an ordinal scale. For example, month is typically encoded via an ordinal scale from 1(January) to 12(December).\nThe main problem with ordinal scale is that the distance between two feature values does not reflect the true cyclical nature of the data. For example, November and January are equidistant to December, while in the ordinal scale the absolute distance between November and December is 1 while that between December and January if 11. While this may work reasonably well for certain algorithms sometime it is benefical to encode the cyclical feature to reflect the cyclical nature of the attribute.\nOne method commonly used for encoding a cyclical feature is to perform a sine and cosine transformation of the feature. For each feature \\(x\\) which takes ordinal values from \\(1,\u0026hellip;,K\\) we use a pair of transformed features. \\( x_{sin} = \\sin\\left(\\frac{2\\pi (x-1)}{K}\\right)\\quad x_{cos} = \\cos\\left(\\frac{2\\pi (x-1)}{K}\\right)\\quad\\text{for}\\quad x=1,...,K \\) Note that is esentially maps the values around a circle. As an added benefit, it is also scaled to the range [-1, 1] which will also aid convergence for neural networks.\nHoliday features # code example Encode country specific holidays as features. We use the python holidays package.\nA buffer can also be specified before and after the holiday using a tapering triangular window. aix360ts ```python from aix360ts.transformers import HolidayFeatures transformer = HolidayFeatures(country=\"IN\", buffer=2, include_holiday_name=True) ``` input ``` sales date 2017-01-01 21.0 2017-01-02 18.0 2017-01-03 9.0 2017-01-04 18.0 2017-01-05 15.0 ... ... 2019-12-27 923.0 2019-12-28 1194.0 2019-12-29 1341.0 2019-12-30 920.0 2019-12-31 748.0 [1095 rows x 1 columns] ``` ouput ``` holiday-IN holiday-IN-name date 2017-01-01 0.000000 no 2017-01-02 0.000000 no 2017-01-03 0.000000 no 2017-01-04 0.000000 no 2017-01-05 0.000000 no 2017-01-06 0.000000 no 2017-01-07 0.000000 no 2017-01-08 0.000000 no 2017-01-09 0.000000 no 2017-01-10 0.000000 no 2017-01-11 0.000000 no 2017-01-12 0.333333 no 2017-01-13 0.666667 no 2017-01-14 1.000000 Makar Sankranti / Pongal 2017-01-15 0.666667 no 2017-01-16 0.333333 no 2017-01-17 0.000000 no 2017-01-18 0.000000 no 2017-01-19 0.000000 no 2017-01-20 0.000000 no 2017-01-21 0.000000 no 2017-01-22 0.000000 no 2017-01-23 0.000000 no 2017-01-24 0.333333 no 2017-01-25 0.666667 no 2017-01-26 1.000000 Republic Day 2017-01-27 0.666667 no 2017-01-28 0.333333 no 2017-01-29 0.000000 no 2017-01-30 0.000000 no 2017-01-31 0.000000 no 2017-02-01 0.000000 no 2017-02-02 0.000000 no 2017-02-03 0.000000 no 2017-02-04 0.000000 no 2017-02-05 0.000000 no 2017-02-06 0.000000 no 2017-02-07 0.000000 no 2017-02-08 0.000000 no 2017-02-09 0.000000 no 2017-02-10 0.000000 no 2017-02-11 0.000000 no 2017-02-12 0.000000 no 2017-02-13 0.000000 no 2017-02-14 0.000000 no 2017-02-15 0.000000 no 2017-02-16 0.000000 no 2017-02-17 0.000000 no 2017-02-18 0.000000 no 2017-02-19 0.000000 no ``` features | | description | type | |:----------------|:---------------------------------------------------|:------------| | holiday-IN | Indicates whether the date is a IN holiday or not. | continuous | | holiday-IN-name | The holiday name. | categorical | Trend features # code example Features to model simple polynomial trend. Adds features of the form \\(t,t^2,..\\). High degrees can cause overfitting, do not go above two unless needed.\naix360ts ```python from aix360ts.transformers import TrendFeatures transformer = TrendFeatures(degree=3) ``` input ``` sales date 2017-01-01 21.0 2017-01-02 18.0 2017-01-03 9.0 2017-01-04 18.0 2017-01-05 15.0 ... ... 2019-12-27 923.0 2019-12-28 1194.0 2019-12-29 1341.0 2019-12-30 920.0 2019-12-31 748.0 [1095 rows x 1 columns] ``` ouput ``` sales_trend_linear sales_trend_quadratic sales_trend_cubic date 2017-01-01 0 0 0 2017-01-02 1 1 1 2017-01-03 2 4 8 2017-01-04 3 9 27 2017-01-05 4 16 64 ... ... ... ... 2019-12-27 1090 1188100 1295029000 2019-12-28 1091 1190281 1298596571 2019-12-29 1092 1192464 1302170688 2019-12-30 1093 1194649 1305751357 2019-12-31 1094 1196836 1309338584 [1095 rows x 3 columns] ``` features | | description | type | |:----------------------|:-----------------------------------------------------------------|:-----------| | sales_trend_linear | Feature to model simple polynomial (of degree 1) trend in sales. | continuous | | sales_trend_quadratic | Feature to model simple polynomial (of degree 2) trend in sales. | continuous | | sales_trend_cubic | Feature to model simple polynomial (of degree 3) trend in sales. | continuous | References # https://www.avanwyk.com/encoding-cyclical-features-for-deep-learning/ "}]
<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on Time Series</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in Introduction on Time Series</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Explainability</title>
      <link>http://localhost:1313/docs/introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/introduction/</guid>
      <description>&lt;h1 id=&#34;explainability&#34;&gt;&#xA;  Explainability&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#explainability&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Explainability&lt;/strong&gt; is the degree to which a human can understand the cause of a decision (or prediction) made by a prediction model &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;time-series-tasks&#34;&gt;&#xA;  Time series tasks&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#time-series-tasks&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Time series classification&lt;/li&gt;&#xA;&lt;li&gt;Time series forecasting&lt;/li&gt;&#xA;&lt;li&gt;Anomaly detection&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;references&#34;&gt;&#xA;  References&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#references&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;&#xA;&lt;hr&gt;&#xA;&lt;ol&gt;&#xA;&lt;li id=&#34;fn:1&#34;&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://christophm.github.io/interpretable-ml-book/&#34;&gt;Interpretable Machine Learning: A Guide for Making Black Box Models Explainable&lt;/a&gt;, Christoph Molnar&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Introduction</title>
      <link>http://localhost:1313/docs/forecasting/introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/forecasting/introduction/</guid>
      <description>&lt;h1 id=&#34;explainability-for-time-series-forecasting&#34;&gt;&#xA;  Explainability for time series forecasting&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#explainability-for-time-series-forecasting&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Explainability&lt;/strong&gt; is the degree to which a human can understand the cause of a decision (or prediction) made by a prediction model &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;types-of-time-series&#34;&gt;&#xA;  Types of time series&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#types-of-time-series&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: right&#34;&gt;type&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;time series only&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;time series + external regressors&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;univariate&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;1 ✔&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;2 ✔&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;multiple univariate&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;3  ✔&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;4 ✔&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;multiple hierarchical univariate&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;5 (phase 2)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;6 (phase 2)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;multivariate&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;7  ✘&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;8  ✘&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;domain-of-explanations&#34;&gt;&#xA;  Domain of explanations&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#domain-of-explanations&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: right&#34;&gt;what&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;explain&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;data&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Explain the time series based on &lt;em&gt;trend&lt;/em&gt;, &lt;em&gt;seasonality&lt;/em&gt; and &lt;em&gt;cyclic&lt;/em&gt; patterns.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;forecaster&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Explains the trained forecaster based on the historical time series.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;forecast&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Explains the forecast at a certain point in time or a certain time interval.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;residual&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Explains the residual on the historical time series to understand where the forecaster is making errors.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;scope-of-explanations&#34;&gt;&#xA;  Scope of explanations&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#scope-of-explanations&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: right&#34;&gt;scope&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;description&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;global explanation&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Explains the forecaster trained on the historical time series.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;local explanation&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Explains the forecast made by a forecaster at a certain point in time.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;group explanation&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Explains the overall forecast made by a forecaster at a certain time interval. The individual local explanations can be used on each instance and then listed or aggregated for the entire interval.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;type-of-explanations&#34;&gt;&#xA;  Type of explanations&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#type-of-explanations&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: right&#34;&gt;type&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;description&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;features based&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Explanation is in terms of features that encode the time series (lag features, date encodings etc.) and external regressors.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;instance based&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Explanation is in terms of the importance or certain time points in the historical time series.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;examples-from-supervised-learning&#34;&gt;&#xA;  Examples from supervised learning&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#examples-from-supervised-learning&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: right&#34;&gt;⚡️&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;features&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;instance&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;global&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;feature importance plots&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;SHAP values&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;(what-if) Partial dependence plots&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;&lt;strong&gt;local&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;LIME&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;prototypes and criticisms&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;SHAP&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;influence functions&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;counterfactual explanation&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;(what-if) counterfactual queries&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;model-agnostic-explaninablity&#34;&gt;&#xA;  Model-agnostic explaninablity&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#model-agnostic-explaninablity&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;We have access to only &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods of a forecaster.&lt;/li&gt;&#xA;&lt;li&gt;We have access to training data ?&lt;/li&gt;&#xA;&lt;li&gt;We have access to features ?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;challenges&#34;&gt;&#xA;  Challenges&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#challenges&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Non-iid nature of data.&lt;/li&gt;&#xA;&lt;li&gt;Robustness. If the the foreecast does not change drastically for the next time point the explanation should not change.&lt;/li&gt;&#xA;&lt;li&gt;Explain prediction intervals and quantile forecasts.&lt;/li&gt;&#xA;&lt;li&gt;Scalability.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;interpretable-models&#34;&gt;&#xA;  Interpretable models&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#interpretable-models&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Some time series forecasting models are inherently interprtable and we aim to wrap up the model specific interpretation whereever available.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Metrics</title>
      <link>http://localhost:1313/docs/metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/metrics/</guid>
      <description>&lt;h1 id=&#34;metrics&#34;&gt;&#xA;  Metrics&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#metrics&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;evaluating-feature-based-local-explanations&#34;&gt;&#xA;  Evaluating feature based local explanations&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#evaluating-feature-based-local-explanations&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Let &#xA;&lt;link rel=&#34;stylesheet&#34; href=&#34;http://localhost:1313/katex/katex.min.css&#34; /&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/katex.min.js&#34;&gt;&lt;/script&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/auto-render.min.js&#34; onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;&lt;span&gt;&#xA;  \(f\)&#xA;&lt;/span&gt;&#xA; be a &lt;strong&gt;black box predictor&lt;/strong&gt; that maps an input &lt;span&gt;&#xA;  \(\mathbf{x} \in \mathbb{R}^d\)&#xA;&lt;/span&gt;&#xA; to an output &lt;span&gt;&#xA;  \(f(\mathbf{x}) \in \mathbb{R}\)&#xA;&lt;/span&gt;&#xA;.&lt;/p&gt;&#xA;&lt;p&gt;An &lt;strong&gt;explanation function&lt;/strong&gt; &lt;span&gt;&#xA;  \(g\)&#xA;&lt;/span&gt;&#xA; takes in a predictor &lt;span&gt;&#xA;  \(f\)&#xA;&lt;/span&gt;&#xA; and an instances &lt;span&gt;&#xA;  \(\mathbf{x}\)&#xA;&lt;/span&gt;&#xA; and returns the feature importance scores &lt;span&gt;&#xA;  \(g(f,\mathbf{x}) \in \mathbb{R}^d\)&#xA;&lt;/span&gt;&#xA;.&lt;/p&gt;&#xA;&lt;p&gt;Let &lt;span&gt;&#xA;  \(\rho: \mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}^{+}\)&#xA;&lt;/span&gt;&#xA; be a &lt;strong&gt;distance metric&lt;/strong&gt; over input instances.&lt;/p&gt;&#xA;&lt;p&gt;Let &lt;span&gt;&#xA;  \(D: \mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}^{+}\)&#xA;&lt;/span&gt;&#xA; be a &lt;strong&gt;distance metric&lt;/strong&gt; over explanations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>TimeSHAP</title>
      <link>http://localhost:1313/docs/forecasting/timeshap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/forecasting/timeshap/</guid>
      <description>&lt;h1 id=&#34;timeshap&#34;&gt;&#xA;  TimeSHAP&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#timeshap&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a  href=&#34;https://github.ibm.com/srom/aix360ts/tree/master/aix360ts/forecasting/explainers/_TimeSHAP&#34;   target=&#34;_blank&#34; rel=&#34;noopener&#34;  class=&#34;book-btn&#34;&gt;code&lt;/a&gt;&#xA;&#xA;&lt;a  href=&#34;https://pages.github.ibm.com/srom/aix360ts/aix360ts.forecasting.explainers.html&#34;   target=&#34;_blank&#34; rel=&#34;noopener&#34;  class=&#34;book-btn&#34;&gt;API docs&lt;/a&gt;&#xA;&#xA;&lt;a  href=&#34;https://github.ibm.com/srom/aix360ts/blob/master/examples/forecasting/explainers/TimeSHAP.py&#34;   target=&#34;_blank&#34; rel=&#34;noopener&#34;  class=&#34;book-btn&#34;&gt;example&lt;/a&gt;&#xA;&#xA;&lt;a  href=&#34;https://pages.github.ibm.com/srom/aix360ts/notebooks/TimeSHAP.html&#34;   target=&#34;_blank&#34; rel=&#34;noopener&#34;  class=&#34;book-btn&#34;&gt;notebook&lt;/a&gt;&#xA;&lt;/p&gt;&#xA;&lt;blockquote class=&#34;book-hint info&#34;&gt;&#xA;  &#xA;TimeSHAP is a feature based post-hoc black box explainer to explain the forecast&#xA;of any univariate time series forecaster using tree-based regressors to build the&#xA;surrogate model and SHAP(SHapley Additive exPlanations) values for the explanations.&#xA;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;For any given univariate time series we first generate a sequence of backtested&#xA;historical forecasts using an (expanding window) splitter. Using the splitter we&#xA;split the time series into a sequence of train an test splits. The expanding window&#xA;splitter uses more and more training data, while keeping the test window size fixed&#xA;to the forecast horizon.  The method is model agnostic in the sense that it needs&#xA;access to only the &lt;code&gt;fit&lt;/code&gt; and &lt;code&gt;predict&lt;/code&gt; methods of the forecaster. The forecaster&#xA;is trained on the train split and evaluated on the test split and all the test split&#xA;predictions are concatenated to get the backtested historical forecasts for each&#xA;step of the forecast horizon. We the construct a surrogate time series forecasting&#xA;task by reducing it to a standard supervised regression problem. For each time point&#xA;we generate a set of interpretable features (lag features, seasonal features,&#xA;date time encodings etc) based on which we need to predict the backtested forecasted&#xA;time series values. The surrogate model is fitted using tree-based regressors like&#xA;XGBoost, CatBoost,LightGBM etc. Explanation is in now in terms of features that&#xA;encode the time series. We mainly rely on the TreeSHAP&#xA;(SHapley Additive exPlanations) algorithm to explain the output of&#xA;ensemble tree models. In order to improve the sensitivity we extend the above&#xA;approach by aggregating multiple explanations from bootstrapped versions of&#xA;the time series.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Interpretable features</title>
      <link>http://localhost:1313/docs/forecasting/features/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/forecasting/features/</guid>
      <description>&lt;h1 id=&#34;encoding-time-series-as-interpretable-features&#34;&gt;&#xA;  Encoding time series as interpretable features&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#encoding-time-series-as-interpretable-features&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;A common machine learning approach to time series forecasting is to reduce it  to a standard &lt;strong&gt;supervised regression&lt;/strong&gt; problem. A regression task takes as input a &#xA;&lt;link rel=&#34;stylesheet&#34; href=&#34;http://localhost:1313/katex/katex.min.css&#34; /&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/katex.min.js&#34;&gt;&lt;/script&gt;&#xA;&lt;script defer src=&#34;http://localhost:1313/katex/auto-render.min.js&#34; onload=&#34;renderMathInElement(document.body);&#34;&gt;&lt;/script&gt;&lt;span&gt;&#xA;  \(d\)&#xA;&lt;/span&gt;&#xA;-dimensional feature vector &lt;span&gt;&#xA;  \(\mathbf{x}\in\mathbb{R}^d\)&#xA;&lt;/span&gt;&#xA; and predicts a scalar &lt;span&gt;&#xA;  \(y \in \mathbb{R}\)&#xA;&lt;/span&gt;&#xA;. The regressor &lt;span&gt;&#xA;  \(y = f(\mathbf{x})\)&#xA;&lt;/span&gt;&#xA; is learnt based on a labelled training dataset &lt;span&gt;&#xA;  \(\left(\mathbf{x}_i,y_i\right)\)&#xA;&lt;/span&gt;&#xA;, for &lt;span&gt;&#xA;  \(i=1,..,n\)&#xA;&lt;/span&gt;&#xA; samples. However there is do direct concept of input features (&lt;span&gt;&#xA;  \(\mathbf{x}\)&#xA;&lt;/span&gt;&#xA;) and output target (&lt;span&gt;&#xA;  \(y\)&#xA;&lt;/span&gt;&#xA;) for a time series.  Instead, we must choose the time series values to be forecasted as the variable to be predicted and use various feature engineering to construct the features that will be used to make predictions for future time steps. For each time point &lt;span&gt;&#xA;  \(t\)&#xA;&lt;/span&gt;&#xA; we generate a feature vector &lt;span&gt;&#xA;  \(\mathbf{x}(t) \in\mathbb{R}^d\)&#xA;&lt;/span&gt;&#xA; based on which we need to predict the observed time series value &lt;span&gt;&#xA;  \(y(t) \in\mathbb{R}\)&#xA;&lt;/span&gt;&#xA;. Here we describe some of the commonly used methods to transform a time series to feature matrix.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Accuracy metrics</title>
      <link>http://localhost:1313/docs/forecasting/accuracy-metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/forecasting/accuracy-metrics/</guid>
      <description>&lt;h1 id=&#34;forecast-accuracy-metrics&#34;&gt;&#xA;  Forecast accuracy metrics&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#forecast-accuracy-metrics&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;A compilation of various metrics used to measure forecast accuracy&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a  href=&#34;https://github.ibm.com/retail-supply-chain/forecasting/blob/master/gists/gist_univariate_metrics.py&#34;   target=&#34;_blank&#34; rel=&#34;noopener&#34;  class=&#34;book-btn&#34;&gt;gist&lt;/a&gt;&#xA;&#xA;&lt;a  href=&#34;https://github.ibm.com/retail-supply-chain/forecasting/tree/master/forecasting/metrics&#34;   target=&#34;_blank&#34; rel=&#34;noopener&#34;  class=&#34;book-btn&#34;&gt;code repo&lt;/a&gt;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Let $y(t)$ be the actual observation for time period $t$ and let $f(t)$ be the forecast for the same time period. Let $n$ the length of the training dataset (number of historical observations), and $h$ the forecasting horizon.&lt;/p&gt;&#xA;&lt;h2 id=&#34;forecast-errors&#34;&gt;&#xA;  Forecast errors&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#forecast-errors&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Based on how we measure the forecast error $e(t)$ at a time point $t$ several metrics are defined. A forecast error is the difference between an observed value and its forecast.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Prediction interval</title>
      <link>http://localhost:1313/docs/forecasting/prediction-interval/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/forecasting/prediction-interval/</guid>
      <description>&lt;h1 id=&#34;prediction-interval&#34;&gt;&#xA;  Prediction interval&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#prediction-interval&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;Prediction intervals express the uncertainty in the forecasts.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Prediction intervals express the uncertainty in the forecasts. This is useful because it provides the user of the forecasts with &lt;em&gt;worst&lt;/em&gt; and &lt;em&gt;best&lt;/em&gt; case estimates and a sense of how depedenable the forecast it. A forecast should be accompanied by a prediction interval giving a range of values the random variable could take with relatively high probability.  The value of prediction intervals is that they express the uncertainty in the forecasts. If we only produce point forecasts, there is no way of telling how accurate the forecasts are. However, if we also produce prediction intervals, then it is clear how much uncertainty is associated with each forecast. For this reason, point forecasts can be of almost no value without the accompanying prediction intervals.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
